{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvKVCZvE5mz8gjokE4LyiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakigigar/bioRxiv-diff/blob/main/bioRxiv-diff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from difflib import unified_diff\n",
        "\n",
        "def extract_biorxiv_text(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    sections = soup.find_all(['div', 'p', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
        "\n",
        "    text_content = \"\"\n",
        "    for section in sections:\n",
        "        text_content += section.get_text(separator=\"\\n\", strip=True) + \"\\n\"\n",
        "\n",
        "    return text_content\n",
        "\n",
        "def compare_versions(text1, text2):\n",
        "\n",
        "    diff = list(unified_diff(text1.splitlines(), text2.splitlines(), lineterm='', n=0))\n",
        "    return diff\n",
        "\n",
        "url1 = \"https://www.biorxiv.org/content/10.1101/2024.04.13.589356v2.full\"\n",
        "url2 = \"https://www.biorxiv.org/content/10.1101/2024.04.13.589356v3.full\"\n",
        "\n",
        "text1 = extract_biorxiv_text(url1)\n",
        "text2 = extract_biorxiv_text(url2)\n",
        "\n",
        "differences = compare_versions(text1, text2)\n",
        "\n",
        "if differences:\n",
        "    print(\"\\nDifferences between the two versions:\")\n",
        "    for line in differences:\n",
        "        if line.startswith('-'):\n",
        "            print(f\"Removed from first: {line[1:].strip()}\")\n",
        "        elif line.startswith('+'):\n",
        "            print(f\"Added in second: {line[1:].strip()}\")\n",
        "        elif line.startswith('@@'):\n",
        "            print(f\"\\n--- Context around line {line}\\n\")\n",
        "else:\n",
        "    print(\"No differences found between the two versions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSdx6vPsi0Wm",
        "outputId": "3c427ba7-f723-4b89-98d8-30f17f3f6955"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -42928 +43969,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -42932 +43977 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -42938 +43983 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -42945 +43990 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -42947 +43992,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -42953 +44000 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -42957 +44004 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -42978 +44025,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -42983,3 +44031 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -42995 +44041 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -43005,2 +44051,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -43029 +44078 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -43043 +44092 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -43045 +44094 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -43053 +44102 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -43056 +44105 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -43058 +44106,0 @@\n",
            "\n",
            "Removed from first: 1.\n",
            "\n",
            "--- Context around line @@ -43158 +44205,0 @@\n",
            "\n",
            "Removed from first: 2.\n",
            "\n",
            "--- Context around line @@ -43201 +44247,0 @@\n",
            "\n",
            "Removed from first: 3.\n",
            "\n",
            "--- Context around line @@ -43228 +44273,0 @@\n",
            "\n",
            "Removed from first: 4.\n",
            "\n",
            "--- Context around line @@ -43305 +44350,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -43325 +44371,0 @@\n",
            "\n",
            "Removed from first: 5.\n",
            "\n",
            "--- Context around line @@ -43377 +44422,0 @@\n",
            "\n",
            "Removed from first: 6.\n",
            "\n",
            "--- Context around line @@ -43445 +44489,0 @@\n",
            "\n",
            "Removed from first: 7.\n",
            "\n",
            "--- Context around line @@ -43546 +44589,0 @@\n",
            "\n",
            "Removed from first: 8.\n",
            "\n",
            "--- Context around line @@ -43597,3 +44640 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -43602 +44642,0 @@\n",
            "\n",
            "Removed from first: 9.\n",
            "\n",
            "--- Context around line @@ -43650 +44689,0 @@\n",
            "\n",
            "Removed from first: 10.\n",
            "\n",
            "--- Context around line @@ -43685 +44723,0 @@\n",
            "\n",
            "Removed from first: 11.\n",
            "\n",
            "--- Context around line @@ -43716,30 +44753,0 @@\n",
            "\n",
            "Removed from first: 12.\n",
            "Removed from first: ↵\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: 13.\n",
            "\n",
            "--- Context around line @@ -43785 +44792,0 @@\n",
            "\n",
            "Removed from first: 14.\n",
            "\n",
            "--- Context around line @@ -43827 +44833,0 @@\n",
            "\n",
            "Removed from first: 15.\n",
            "\n",
            "--- Context around line @@ -43852 +44857,0 @@\n",
            "\n",
            "Removed from first: 16.\n",
            "\n",
            "--- Context around line @@ -43877 +44881,0 @@\n",
            "\n",
            "Removed from first: 17.\n",
            "\n",
            "--- Context around line @@ -43978 +44981,0 @@\n",
            "\n",
            "Removed from first: 18.\n",
            "\n",
            "--- Context around line @@ -43995 +44997,0 @@\n",
            "\n",
            "Removed from first: 19.\n",
            "\n",
            "--- Context around line @@ -44075,2 +45077,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -44082 +45084,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -44090 +45097,0 @@\n",
            "\n",
            "Removed from first: 20.\n",
            "\n",
            "--- Context around line @@ -44131 +45137,0 @@\n",
            "\n",
            "Removed from first: 21.\n",
            "\n",
            "--- Context around line @@ -44148,3 +45154 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -44155 +45158,0 @@\n",
            "\n",
            "Removed from first: 22.\n",
            "\n",
            "--- Context around line @@ -44198 +45200,0 @@\n",
            "\n",
            "Removed from first: 23.\n",
            "\n",
            "--- Context around line @@ -44276 +45277,0 @@\n",
            "\n",
            "Removed from first: 24.\n",
            "\n",
            "--- Context around line @@ -44307 +45307,0 @@\n",
            "\n",
            "Removed from first: 25.\n",
            "\n",
            "--- Context around line @@ -44442 +45442 @@\n",
            "\n",
            "Removed from first: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods – NanoCount (\n",
            "Added in second: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods, namely NanoCount (\n",
            "\n",
            "--- Context around line @@ -44444,3 +45444 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ) – attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "Added in second: ), attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "\n",
            "--- Context around line @@ -44454 +45452 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -44456,4 +45454,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -44461 +45457 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -44465 +45461 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -44469 +45465 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -44474 +45470,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -44476 +45473 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -44480,2 +45477,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -44500 +45497 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -44508 +45505 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -44515 +45512 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -44534 +45531 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -44536 +45533 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -44538 +45535 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -44545 +45542 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -44549 +45546 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -44554 +45551 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -44556 +45553 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -44558 +45555 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -44560 +45557 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -44562 +45559 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -44566 +45563 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -44572 +45569 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -44576 +45573 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -44600 +45597,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -44603,3 +45606,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -44609 +45612,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -44618 +45629,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -44621,3 +45635 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -44661 +45673,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -44668 +45683,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44696 +45712,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44698 +45715,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -44715 +45734,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -44719,13 +45742,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -44745,27 +45762,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -44796 +45804,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -44817 +45835,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -44819 +45838,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -44821 +45841,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -44828 +45849,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44838 +45860,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -44842 +45868,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -44844,2 +45878 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -44849 +45882,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44852 +45888,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -44863 +45902,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -44866 +45907,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -44868 +45910,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -44882 +45930 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -44885 +45933,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -44899 +45949,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44901 +45952,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -44909 +45962,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44918 +45972,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -44920 +45975,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -44928 +45985,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -44930,3 +45989,27 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -44948 +46031,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -44950 +46035,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -44954 +46043 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -44960 +46049 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -44967 +46056 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -44969 +46058,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -44975 +46066 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -44979 +46070 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -45000 +46091,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -45005,3 +46097 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -45017 +46107 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -45027,2 +46117,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -45051 +46144 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -45065 +46158 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -45067 +46160 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -45075 +46168 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -45078 +46171 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -45080 +46172,0 @@\n",
            "\n",
            "Removed from first: 1.\n",
            "\n",
            "--- Context around line @@ -45180 +46271,0 @@\n",
            "\n",
            "Removed from first: 2.\n",
            "\n",
            "--- Context around line @@ -45223 +46313,0 @@\n",
            "\n",
            "Removed from first: 3.\n",
            "\n",
            "--- Context around line @@ -45250 +46339,0 @@\n",
            "\n",
            "Removed from first: 4.\n",
            "\n",
            "--- Context around line @@ -45327 +46416,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -45347 +46437,0 @@\n",
            "\n",
            "Removed from first: 5.\n",
            "\n",
            "--- Context around line @@ -45399 +46488,0 @@\n",
            "\n",
            "Removed from first: 6.\n",
            "\n",
            "--- Context around line @@ -45467 +46555,0 @@\n",
            "\n",
            "Removed from first: 7.\n",
            "\n",
            "--- Context around line @@ -45568 +46655,0 @@\n",
            "\n",
            "Removed from first: 8.\n",
            "\n",
            "--- Context around line @@ -45619,3 +46706 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -45624 +46708,0 @@\n",
            "\n",
            "Removed from first: 9.\n",
            "\n",
            "--- Context around line @@ -45672 +46755,0 @@\n",
            "\n",
            "Removed from first: 10.\n",
            "\n",
            "--- Context around line @@ -45707 +46789,0 @@\n",
            "\n",
            "Removed from first: 11.\n",
            "\n",
            "--- Context around line @@ -45738,30 +46819,0 @@\n",
            "\n",
            "Removed from first: 12.\n",
            "Removed from first: ↵\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: 13.\n",
            "\n",
            "--- Context around line @@ -45807 +46858,0 @@\n",
            "\n",
            "Removed from first: 14.\n",
            "\n",
            "--- Context around line @@ -45849 +46899,0 @@\n",
            "\n",
            "Removed from first: 15.\n",
            "\n",
            "--- Context around line @@ -45874 +46923,0 @@\n",
            "\n",
            "Removed from first: 16.\n",
            "\n",
            "--- Context around line @@ -45899 +46947,0 @@\n",
            "\n",
            "Removed from first: 17.\n",
            "\n",
            "--- Context around line @@ -46000 +47047,0 @@\n",
            "\n",
            "Removed from first: 18.\n",
            "\n",
            "--- Context around line @@ -46017 +47063,0 @@\n",
            "\n",
            "Removed from first: 19.\n",
            "\n",
            "--- Context around line @@ -46097,2 +47143,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -46104 +47150,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -46112 +47163,0 @@\n",
            "\n",
            "Removed from first: 20.\n",
            "\n",
            "--- Context around line @@ -46153 +47203,0 @@\n",
            "\n",
            "Removed from first: 21.\n",
            "\n",
            "--- Context around line @@ -46170,3 +47220 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -46177 +47224,0 @@\n",
            "\n",
            "Removed from first: 22.\n",
            "\n",
            "--- Context around line @@ -46220 +47266,0 @@\n",
            "\n",
            "Removed from first: 23.\n",
            "\n",
            "--- Context around line @@ -46298 +47343,0 @@\n",
            "\n",
            "Removed from first: 24.\n",
            "\n",
            "--- Context around line @@ -46329 +47373,0 @@\n",
            "\n",
            "Removed from first: 25.\n",
            "\n",
            "--- Context around line @@ -46464 +47508 @@\n",
            "\n",
            "Removed from first: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods – NanoCount (\n",
            "Added in second: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods, namely NanoCount (\n",
            "\n",
            "--- Context around line @@ -46466,3 +47510 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ) – attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "Added in second: ), attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "\n",
            "--- Context around line @@ -46476 +47518 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -46478,4 +47520,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -46483 +47523 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -46487 +47527 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -46491 +47531 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -46496 +47536,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -46498 +47539 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -46502,2 +47543,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -46522 +47563 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -46530 +47571 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -46537 +47578 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -46556 +47597 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -46558 +47599 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -46560 +47601 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -46567 +47608 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -46571 +47612 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -46576 +47617 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -46578 +47619 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -46580 +47621 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -46582 +47623 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -46584 +47625 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -46588 +47629 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -46594 +47635 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -46598 +47639 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -46622 +47663,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -46625,3 +47672,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -46631 +47678,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -46640 +47695,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -46643,3 +47701 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -46683 +47739,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -46690 +47749,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46718 +47778,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46720 +47781,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -46737 +47800,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -46741,13 +47808,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -46767,27 +47828,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -46818 +47870,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -46839 +47901,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -46841 +47904,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -46843 +47907,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -46850 +47915,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46860 +47926,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -46864 +47934,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -46866,2 +47944 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -46871 +47948,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46874 +47954,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -46885 +47968,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -46888 +47973,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -46890 +47976,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -46904 +47996 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -46907 +47999,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -46921 +48015,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46923 +48018,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -46931 +48028,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46940 +48038,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -46942 +48041,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -46950 +48051,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -46952,3 +48055,27 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -46970 +48097,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -46972 +48101,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -46976 +48109 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -46982 +48115 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -46989 +48122 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -46991 +48124,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -46997 +48132 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -47001 +48136 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -47022 +48157,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -47027,3 +48163 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -47039 +48173 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -47049,2 +48183,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -47073 +48210 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -47087 +48224 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -47089 +48226 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -47097 +48234 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -47100 +48237 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -47102 +48238,0 @@\n",
            "\n",
            "Removed from first: 1.\n",
            "\n",
            "--- Context around line @@ -47202 +48337,0 @@\n",
            "\n",
            "Removed from first: 2.\n",
            "\n",
            "--- Context around line @@ -47245 +48379,0 @@\n",
            "\n",
            "Removed from first: 3.\n",
            "\n",
            "--- Context around line @@ -47272 +48405,0 @@\n",
            "\n",
            "Removed from first: 4.\n",
            "\n",
            "--- Context around line @@ -47349 +48482,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -47369 +48503,0 @@\n",
            "\n",
            "Removed from first: 5.\n",
            "\n",
            "--- Context around line @@ -47421 +48554,0 @@\n",
            "\n",
            "Removed from first: 6.\n",
            "\n",
            "--- Context around line @@ -47489 +48621,0 @@\n",
            "\n",
            "Removed from first: 7.\n",
            "\n",
            "--- Context around line @@ -47590 +48721,0 @@\n",
            "\n",
            "Removed from first: 8.\n",
            "\n",
            "--- Context around line @@ -47641,3 +48772 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -47646 +48774,0 @@\n",
            "\n",
            "Removed from first: 9.\n",
            "\n",
            "--- Context around line @@ -47694 +48821,0 @@\n",
            "\n",
            "Removed from first: 10.\n",
            "\n",
            "--- Context around line @@ -47729 +48855,0 @@\n",
            "\n",
            "Removed from first: 11.\n",
            "\n",
            "--- Context around line @@ -47760,30 +48885,0 @@\n",
            "\n",
            "Removed from first: 12.\n",
            "Removed from first: ↵\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: 13.\n",
            "\n",
            "--- Context around line @@ -47829 +48924,0 @@\n",
            "\n",
            "Removed from first: 14.\n",
            "\n",
            "--- Context around line @@ -47871 +48965,0 @@\n",
            "\n",
            "Removed from first: 15.\n",
            "\n",
            "--- Context around line @@ -47896 +48989,0 @@\n",
            "\n",
            "Removed from first: 16.\n",
            "\n",
            "--- Context around line @@ -47921 +49013,0 @@\n",
            "\n",
            "Removed from first: 17.\n",
            "\n",
            "--- Context around line @@ -48022 +49113,0 @@\n",
            "\n",
            "Removed from first: 18.\n",
            "\n",
            "--- Context around line @@ -48039 +49129,0 @@\n",
            "\n",
            "Removed from first: 19.\n",
            "\n",
            "--- Context around line @@ -48119,2 +49209,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -48126 +49216,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -48134 +49229,0 @@\n",
            "\n",
            "Removed from first: 20.\n",
            "\n",
            "--- Context around line @@ -48175 +49269,0 @@\n",
            "\n",
            "Removed from first: 21.\n",
            "\n",
            "--- Context around line @@ -48192,3 +49286 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -48199 +49290,0 @@\n",
            "\n",
            "Removed from first: 22.\n",
            "\n",
            "--- Context around line @@ -48242 +49332,0 @@\n",
            "\n",
            "Removed from first: 23.\n",
            "\n",
            "--- Context around line @@ -48320 +49409,0 @@\n",
            "\n",
            "Removed from first: 24.\n",
            "\n",
            "--- Context around line @@ -48351 +49439,0 @@\n",
            "\n",
            "Removed from first: 25.\n",
            "\n",
            "--- Context around line @@ -48486 +49574 @@\n",
            "\n",
            "Removed from first: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods – NanoCount (\n",
            "Added in second: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods, namely NanoCount (\n",
            "\n",
            "--- Context around line @@ -48488,3 +49576 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ) – attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "Added in second: ), attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "\n",
            "--- Context around line @@ -48498 +49584 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -48500,4 +49586,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -48505 +49589 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -48509 +49593 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -48513 +49597 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -48518 +49602,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -48520 +49605 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -48524,2 +49609,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -48544 +49629 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -48552 +49637 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -48559 +49644 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -48578 +49663 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -48580 +49665 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -48582 +49667 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -48589 +49674 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -48593 +49678 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -48598 +49683 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -48600 +49685 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -48602 +49687 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -48604 +49689 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -48606 +49691 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -48610 +49695 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -48616 +49701 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -48620 +49705 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -48644 +49729,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -48647,3 +49738,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -48653 +49744,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -48662 +49761,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -48665,3 +49767 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -48705 +49805,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -48712 +49815,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48740 +49844,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48742 +49847,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -48759 +49866,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -48763,13 +49874,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -48789,27 +49894,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -48840 +49936,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -48861 +49967,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -48863 +49970,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -48865 +49973,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -48872 +49981,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48882 +49992,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -48886 +50000,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -48888,2 +50010 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -48893 +50014,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48896 +50020,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -48907 +50034,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -48910 +50039,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -48912 +50042,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -48926 +50062 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -48929 +50065,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -48943 +50081,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48945 +50084,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -48953 +50094,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48962 +50104,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -48964 +50107,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -48972 +50117,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -48974,3 +50121,27 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -48992 +50163,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -48994 +50167,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -48998 +50175 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -49004 +50181 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -49011 +50188 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -49013 +50190,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -49019 +50198 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -49023 +50202 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -49044 +50223,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -49049,3 +50229 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -49061 +50239 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -49071,2 +50249,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -49095 +50276 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -49109 +50290 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -49111 +50292 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -49119 +50300 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -49122 +50303 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -49124 +50304,0 @@\n",
            "\n",
            "Removed from first: 1.\n",
            "\n",
            "--- Context around line @@ -49224 +50403,0 @@\n",
            "\n",
            "Removed from first: 2.\n",
            "\n",
            "--- Context around line @@ -49267 +50445,0 @@\n",
            "\n",
            "Removed from first: 3.\n",
            "\n",
            "--- Context around line @@ -49294 +50471,0 @@\n",
            "\n",
            "Removed from first: 4.\n",
            "\n",
            "--- Context around line @@ -49371 +50548,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -49391 +50569,0 @@\n",
            "\n",
            "Removed from first: 5.\n",
            "\n",
            "--- Context around line @@ -49443 +50620,0 @@\n",
            "\n",
            "Removed from first: 6.\n",
            "\n",
            "--- Context around line @@ -49511 +50687,0 @@\n",
            "\n",
            "Removed from first: 7.\n",
            "\n",
            "--- Context around line @@ -49612 +50787,0 @@\n",
            "\n",
            "Removed from first: 8.\n",
            "\n",
            "--- Context around line @@ -49663,3 +50838 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -49668 +50840,0 @@\n",
            "\n",
            "Removed from first: 9.\n",
            "\n",
            "--- Context around line @@ -49716 +50887,0 @@\n",
            "\n",
            "Removed from first: 10.\n",
            "\n",
            "--- Context around line @@ -49751 +50921,0 @@\n",
            "\n",
            "Removed from first: 11.\n",
            "\n",
            "--- Context around line @@ -49782,30 +50951,0 @@\n",
            "\n",
            "Removed from first: 12.\n",
            "Removed from first: ↵\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: 13.\n",
            "\n",
            "--- Context around line @@ -49851 +50990,0 @@\n",
            "\n",
            "Removed from first: 14.\n",
            "\n",
            "--- Context around line @@ -49893 +51031,0 @@\n",
            "\n",
            "Removed from first: 15.\n",
            "\n",
            "--- Context around line @@ -49918 +51055,0 @@\n",
            "\n",
            "Removed from first: 16.\n",
            "\n",
            "--- Context around line @@ -49943 +51079,0 @@\n",
            "\n",
            "Removed from first: 17.\n",
            "\n",
            "--- Context around line @@ -50044 +51179,0 @@\n",
            "\n",
            "Removed from first: 18.\n",
            "\n",
            "--- Context around line @@ -50061 +51195,0 @@\n",
            "\n",
            "Removed from first: 19.\n",
            "\n",
            "--- Context around line @@ -50141,2 +51275,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -50148 +51282,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -50156 +51295,0 @@\n",
            "\n",
            "Removed from first: 20.\n",
            "\n",
            "--- Context around line @@ -50197 +51335,0 @@\n",
            "\n",
            "Removed from first: 21.\n",
            "\n",
            "--- Context around line @@ -50214,3 +51352 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -50221 +51356,0 @@\n",
            "\n",
            "Removed from first: 22.\n",
            "\n",
            "--- Context around line @@ -50264 +51398,0 @@\n",
            "\n",
            "Removed from first: 23.\n",
            "\n",
            "--- Context around line @@ -50342 +51475,0 @@\n",
            "\n",
            "Removed from first: 24.\n",
            "\n",
            "--- Context around line @@ -50373 +51505,0 @@\n",
            "\n",
            "Removed from first: 25.\n",
            "\n",
            "--- Context around line @@ -50516 +51648 @@\n",
            "\n",
            "Removed from first: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods – NanoCount (\n",
            "Added in second: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods, namely NanoCount (\n",
            "\n",
            "--- Context around line @@ -50518,3 +51650 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ) – attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "Added in second: ), attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "\n",
            "--- Context around line @@ -50552 +51682 @@\n",
            "\n",
            "Removed from first: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods – NanoCount (\n",
            "Added in second: Few tools, including FLAIR and Bambu, track read-to-transcript assignments, but this functionality is integrated into more complex pipelines that also identify novel isoforms in addition to quantifying known transcripts. A standalone tool capable of performing read assignment and quantification on any input transcriptome can be paired with other methods focusing on transcriptome assembly and could therefore enable users to investigate any transcriptome of their choice. However, this need remains largely unmet, with only a few recent methods, namely NanoCount (\n",
            "\n",
            "--- Context around line @@ -50554,3 +51684 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ) – attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "Added in second: ), attempting to address it by quantifying transcripts, yet still lacking the ability to assign specific reads to transcripts.\n",
            "\n",
            "--- Context around line @@ -50564 +51692 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -50566,4 +51694,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -50571 +51697 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -50575 +51701 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -50579 +51705 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -50584 +51710,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -50586 +51713 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -50590,2 +51717,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -50610 +51737 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -50618 +51745 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -50625 +51752 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -50644 +51771 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -50646 +51773 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -50648 +51775 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -50655 +51782 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -50659 +51786 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -50664 +51791 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -50666 +51793 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -50668 +51795 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -50670 +51797 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -50672 +51799 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -50676 +51803 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -50682 +51809 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -50686 +51813 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -50689 +51816 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -50691,4 +51818,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -50696 +51821 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -50700 +51825 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -50704 +51829 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -50709 +51834,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -50711 +51837 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -50715,2 +51841,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -50735 +51861 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -50743 +51869 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -50750 +51876 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -50755 +51881 @@\n",
            "\n",
            "Removed from first: We first compared TranSigner against two existing quantification-only tools: NanoCount (\n",
            "Added in second: We first compared TranSigner against an existing quantification-only tool, NanoCount (\n",
            "\n",
            "--- Context around line @@ -50757,4 +51883,2 @@\n",
            "\n",
            "Removed from first: ) and Oarfish (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ). We benchmarked all three tools using five simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Removed from first: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s and Oarfish’s, as illustrated in\n",
            "Added in second: ). We benchmarked all three tools using five sets of simulated ONT reads: three sets of direct RNA reads and two sets of cDNA reads. The reads were simulated from protein-coding and long non-coding transcripts in the GRCh38 RefSeq annotation (release 110), and then each tool was provided with both the simulated reads as well as the full RefSeq annotation as the target transcriptome (see Methods for a full description of the simulated datasets). For simplicity, we will refer to the transcripts from which the reads were simulated as the origin transcripts. To estimate how accurately a tool assigns a read to its respective origin, we conducted both linear and nonlinear correlation analyses between the expected read counts and each tool’s estimates, using Pearson’s correlation coefficients (PCCs) between raw read counts and Spearman’s correlation coefficients (SCCs) between log-transformed read counts, respectively. A linear correlation analysis evaluates the ability of a tool to assign each read to a transcript, while a nonlinear correlation analysis assesses how well estimates capture monotonic trends in gene expression patterns.\n",
            "Added in second: In both analyses, we observed that TranSigner’s estimates had stronger correlations with the ground truth compared to NanoCount’s, as illustrated in\n",
            "\n",
            "--- Context around line @@ -50762 +51886 @@\n",
            "\n",
            "Removed from first: , which shows results from one dataset typical of all three simulated ONT dRNA datasets (see Supplementary Table S3 for SCC and PCC values across all three simulated read sets). In both log-transformed (\n",
            "Added in second: , which shows results from one dataset typical of all three simulated ONT direct RNA datasets (see Supplementary Table S3 for the SCC and PCC values on each read set). In both log-transformed (\n",
            "\n",
            "--- Context around line @@ -50766 +51890 @@\n",
            "\n",
            "Removed from first: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s and OarFish’s results; the accumulations of dots either well above in the case of NanoCount or well below the diagonal in the case of Oarfish reveal NanoCount’s tendency to underestimate and Oarfish’s tendency to overestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997, and OarFish’s were 0.632 and 0.985, respectively (see Supplementary Table S3 for correlation values on each dataset). TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (Supplementary Figure S1, Supplementary Tables S4).\n",
            "Added in second: ) read count correlation scatter plots, TranSigner shows higher concentrations of dots near the diagonal. However, this feature is not as pronounced in the plots of NanoCount’s results; the accumulations of dots well below the diagonal in the case of NanoCount reveal the tool’s tendency to underestimate the read counts. On the simulated ONT direct RNA datasets, TranSigner’s average SCC and PCC values were 0.867 and 0.999, whereas NanoCount’s were 0.667 and 0.997. TranSigner also achieves higher correlations with the ground truth when applied to the simulated ONT cDNA datasets (see Supplementary Figure S1, Supplementary Tables S4).\n",
            "\n",
            "--- Context around line @@ -50770 +51894 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -50776,2 +51900,2 @@\n",
            "\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Removed from first: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount, Oarfish and Transigner on a simulated ONT dRNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "Added in second: Correlation scatter plots comparing expected read counts to the read count estimates generated by NanoCount and Transigner on a simulated ONT direct RNA reads set. All tools were provided with the full RefSeq annotation from which the reads were simulated from. A: scatter plots showing the nonlinear correlations between the log-transformed ground truth and the estimated read counts. B: scatter plots showing the linear correlations between the raw ground truth and estimated read counts. The x- and y-axes were limited to [0, 2000] for demonstration purposes.\n",
            "\n",
            "--- Context around line @@ -50783 +51907,2 @@\n",
            "\n",
            "Removed from first: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification. Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "Added in second: ). This is one reason why most long-read processing tools identify which transcripts are present before quantification.\n",
            "Added in second: Identifying novel isoforms not present in the annotation, as well as determining which of the known mRNA variants are expressed can lead to better quantification of expressed transcripts. This is illustrated by our results in\n",
            "\n",
            "--- Context around line @@ -50785 +51910 @@\n",
            "\n",
            "Removed from first: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets). By contrast, Oarfish’s performance stayed consistent, suggesting that the tool is less dependent on the quality of the input transcriptome.\n",
            "Added in second: , where we show that the average nonlinear correlation coefficients between estimated and true read counts improve for both TranSigner and NanoCount when just the origin transcripts are provided in the input instead of the full reference annotation (see Supplementary Tables S3 and S4 for SCC and PCC values across all simulated ONT direct RNA and cDNA data sets).\n",
            "\n",
            "--- Context around line @@ -50789 +51914 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "\n",
            "--- Context around line @@ -50795,2 +51920,2 @@\n",
            "\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Removed from first: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner, NanoCount, and Oarfish on the simulated ONT reads. A shows the averages across 3 simulated ONT dRNA read sets, while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "Added in second: SCC values observed when either the origin transcriptome (blue in A, orange in B) or the full RefSeq annotation (grey) is used to run TranSigner and NanoCount on the simulated ONT reads. A shows the averages across 3 simulated ONT direct RNA read sets , while B shows the averages across 2 simulated ONT cDNA read sets.\n",
            "\n",
            "--- Context around line @@ -50798 +51923 @@\n",
            "\n",
            "Removed from first: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner, OarFish, and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "Added in second: Achieving an accurate transcriptome remains a challenging problem, with different tools obtaining varying accuracies in this task, while also relying to varying degrees on the input reference annotation. Using the same simulated ONT data sets (3 direct RNA, 2 cDNA) we used to benchmark TranSigner and NanoCount, we evaluated existing tools’ ability to handle incompleteness in the input guide annotations. To do this, we randomly sampled the full RefSeq annotation to include varying percentages–between 0% and 100% with increments of 5%–of the origin transcripts and provided the resulting annotations as guides to StringTie2, FLAIR, and Bambu. We did not include ESPRESSO in this comparison, as processing a single simulated data set took more than 24h to process. We also randomly sampled each percentage of retained origin transcripts three times (see Methods for further details).\n",
            "\n",
            "--- Context around line @@ -50825 +51950 @@\n",
            "\n",
            "Removed from first: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT dRNA and cDNA benchmarks (\n",
            "Added in second: (also see Supplementary Tables S5 and S6 for results on all input datasets). Except for StringTie2 + TranSigner, every tool experienced a drastic drop in SCC values as the percentage of origin transcripts decreased. TranSigner had the highest correlation values when the input guide annotation contained nearly all origin transcripts. However, when 90% or fewer of the origin transcripts were retained in the guide annotation, StringTie2 + TranSigner yielded the best SCC values in both ONT direct RNA and cDNA benchmarks (\n",
            "\n",
            "--- Context around line @@ -50833 +51958 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -50839,2 +51964,2 @@\n",
            "\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Removed from first: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT dRNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT dRNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "Added in second: Correlation coefficients between true and estimated abundances (read counts in A and B, and per base read coverages in C) computed at varying percent guide annotations computed using simulated ONT data. A: SCC values in simulated ONT direct RNA data. Average SCCs across 9 independent observations (3 read sets, 3 guide samplings) shown. B: SCC values in simulated ONT cDNA data. Average SCCs across 6 independent observations (3 read sets, 2 guide samplings) shown. C: PCC values for both ONT direct RNA (solid line) and cDNA (dotted line) simulated reads. Averages across multiple samples are shown. Different colors indicate different tools.\n",
            "\n",
            "--- Context around line @@ -50848 +51973 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -50854,2 +51979,2 @@\n",
            "\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Removed from first: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT dRNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "Added in second: Read-to-transcript assignment accuracies for TranSigner, StringTie + TranSigner, Bambu, and FLAIR on simulated ONT data. Solid lines represent performance on ONT direct RNA reads and dotted lines represent performance on ONT cDNA reads. Three metrics – sensivitiy, precision, recall – are shown from top to bottom. Standard error of measurement (SEM) intervals are shown as shaded areas.\n",
            "\n",
            "--- Context around line @@ -50875 +52000 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -50877 +52002 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -50879 +52004 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -50886 +52011 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -50890 +52015 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -50895 +52020 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -50897 +52022 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -50899 +52024 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -50901 +52026 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -50903 +52028 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -50907 +52032 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -50913 +52038 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -50917 +52042 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -50941 +52066 @@\n",
            "\n",
            "Removed from first: Specifically, we assessed the long read-based abundance estimates using the three quantification-only tools we used with simulated data: Oarfish, NanoCount, and TranSigner. All tools were provided with a StringTie-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM estimates. As previously done for benchmarking long-read quantification tools (\n",
            "Added in second: Specifically, we assessed the long read-based abundance estimates by two quantification-only tools we benchmarked with simulated data: NanoCount and TranSigner. All tools were provided with a StringTie2-assembled transcriptome, which represents a typical use for these tools where users provide transcriptomes assembled from samples of their interest. We used each tool’s abundance estimates to conduct nonlinear correlation analyses between the short read-derived TPM estimates and long read-derived CPM. As previously done for benchmarking long-read quantification tools (\n",
            "\n",
            "--- Context around line @@ -50943 +52068 @@\n",
            "\n",
            "Removed from first: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript. We used Salmon (\n",
            "Added in second: ), we assumed that a higher correlation between long read- and short read-derived abundance estimates is indicative of a higher quantification accuracy. Since none of the three quantification-only tools we used include TPMs in their output, we processed the read counts they provide to obtain counts per million (CPM) estimates, which are equivalent to TPMs in a long-read RNA-seq experiment where each read is considered to represent a transcript (see Methods for the read counts to CPM conversion equation). We used Salmon (\n",
            "\n",
            "--- Context around line @@ -50945 +52070 @@\n",
            "\n",
            "Removed from first: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Methods). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "Added in second: ) to obtain TPM estimates on StringTie2 assemblies, using the Illumina short-read datasets (see Supplementary Text 3). As transcripts with low abundances are prone to misassembly and are often excluded from downstream analyses, we only included in our results transcripts with > 1 TPM as estimated by Salmon.\n",
            "\n",
            "--- Context around line @@ -50952 +52077 @@\n",
            "\n",
            "Removed from first: , TranSigner consistently achieved higher correlations than other quantification-only tools as well as than StringTie2’s estimates, across all read types (Supplementary Tables S10). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets, where NanoCount was the second best. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "Added in second: , TranSigner consistently achieved higher correlations than NanoCount as well as StringTie2, across all read types (see Supplementary Tables S10 for the SCC and PCC values on each pair). TranSigner improved StringTie2’s estimates to varying degrees, with the highest improvements observed in the ONT PCR-cDNA data sets. Note that NanoCount was not evaluated on PacBio data as it was designed specifically to work with ONT data only.\n",
            "\n",
            "--- Context around line @@ -50956 +52081 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -50962,2 +52087,2 @@\n",
            "\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Removed from first: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount, Oarfish, and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "Added in second: Box plots showing the distribution of SCC values between the short- and long-read-derived transcript abundances for 12 different pairs of human data sets. NanoCount and TranSigner were run on the StringTie2 assemblies on the long-read samples. StringTie2’s intial estimates are shown in the rightmost column for reference. Four distinct read types are shown in different colors.\n",
            "\n",
            "--- Context around line @@ -50969 +52094 @@\n",
            "\n",
            "Removed from first: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + <A quantification-only tool> at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "Added in second: . To investigate how quantification accuracies vary at different levels of expression, we evaluated the performance of StringTie2 and StringTie2 + < a quantification-only tool > at progressively increasing TPM thresholds: 1, 5, 10, 15, and 20. For this experiment, we selected eight\n",
            "\n",
            "--- Context around line @@ -50971 +52096 @@\n",
            "\n",
            "Removed from first: pairs (four ONT dRNA, four ONT cDNA) and three\n",
            "Added in second: pairs (four ONT direct RNA, four ONT cDNA) and three\n",
            "\n",
            "--- Context around line @@ -50973 +52098 @@\n",
            "\n",
            "Removed from first: pairs (all ONT dRNA). We benchmarked TranSigner, Oarfish, and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "Added in second: pairs (all ONT direct RNA). We benchmarked TranSigner’s and NanoCount’s performances when run on unguided StringTie2 assemblies, consistent with the previous analysis. As illustrated in\n",
            "\n",
            "--- Context around line @@ -50975 +52100 @@\n",
            "\n",
            "Removed from first: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than all other tools, with the best improvements in SCC values obtained on the\n",
            "Added in second: , when TranSigner was applied to StringTie2’s output, it achieved higher nonlinear correlations between short- and long-read TPM estimates than NanoCount, with the best improvements in SCC values obtained on the\n",
            "\n",
            "--- Context around line @@ -50977 +52102 @@\n",
            "\n",
            "Removed from first: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds. Oarfish also showed stronger correlations for transcripts with higher abundances as indicated by increasing SCC values with higher TPM thresholds.\n",
            "Added in second: ONT PCR-cDNA reads. These improvements were more pronounced for higher TPM thresholds.\n",
            "\n",
            "--- Context around line @@ -50981 +52106 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -50987 +52112 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -50991 +52116 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -50997 +52122 @@\n",
            "\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -51003 +52128 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -51007,2 +52132,2 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Removed from first: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount, Oarfish, TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "Added in second: ONT direct RNA data sets.\n",
            "Added in second: Correlation coefficient values between short- and long-read-derived transcript abundances estimated by NanoCount and TranSigner when run on StringTie2 assemblies, as well as StringTie2 itself, on paired\n",
            "\n",
            "--- Context around line @@ -51014 +52139 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "Added in second: ONT direct RNA data sets. B: average SCC values across increasing TPM thresholds on\n",
            "\n",
            "--- Context around line @@ -51018 +52143 @@\n",
            "\n",
            "Removed from first: ONT dRNA data sets.\n",
            "Added in second: ONT direct RNA data sets.\n",
            "\n",
            "--- Context around line @@ -51046 +52171,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -51049,3 +52180,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -51055 +52186,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -51064 +52203,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51067,3 +52209 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -51107 +52247,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51114 +52257,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51142 +52286,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51144 +52289,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -51161 +52308,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -51165,13 +52316,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -51191,27 +52336,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -51242 +52378,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -51263 +52409,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -51265 +52412,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -51267 +52415,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -51274 +52423,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51284 +52434,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -51288 +52442,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -51290,2 +52452 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -51295 +52456,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51298 +52462,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -51309 +52476,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -51312 +52481,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -51314 +52484,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -51328 +52504 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -51331 +52507,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -51345 +52523,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51347 +52526,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -51355 +52536,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51364 +52546,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51366 +52549,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -51374 +52559,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -51376,3 +52563,27 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -51394 +52605,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -51396 +52609,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -51400 +52617 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -51406 +52623 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -51413 +52630 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -51415 +52632,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -51421 +52640 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -51425 +52644 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -51446 +52665,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51451,3 +52671 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -51463 +52681 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -51473,2 +52691,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51497 +52718 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -51518 +52739,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -51521,3 +52748,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -51527 +52754,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -51536 +52771,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51539,3 +52777 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -51579 +52815,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51586 +52825,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51614 +52854,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51616 +52857,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -51633 +52876,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -51637,13 +52884,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -51663,27 +52904,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -51714 +52946,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -51735 +52977,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -51737 +52980,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -51739 +52983,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -51746 +52991,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51748,0 +52995,163 @@\n",
            "\n",
            "Added in second: Alignment\n",
            "Added in second: We used minimap2 with parameter -N 181 to align the long reads to the set of input transcripts (\n",
            "Added in second: Li, 2018\n",
            "Added in second: ,\n",
            "Added in second: 2021\n",
            "Added in second: ). By default, minimap2 limits the maximum number of secondary alignments to 5. We observed that the number of true positives (correct read to transcript alignments) increases when we retain more secondary alignments, so we set -N to 181, the highest number of transcripts in a single gene locus according to the RefSeq release 110 annotation on the human GRCh38 genome, assuming this is the maximum number of secondary alignments a read can have. This strategy provides rough, preliminary estimates on the compatibility between reads and transcripts, without excluding any read and transcript pair for having suboptimal alignment scores. The user can freely adjust this parameter by specifying it in TranSigner’s input, which will then pass it to minimap2.\n",
            "Added in second: Alignment-guided expectation-maximization algorithm (AG-EM)\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Figure 9\n",
            "Added in second: and\n",
            "Added in second: Eqs. 1\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "Added in second: Update rules\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "Added in second: –at some iteration\n",
            "Added in second: n\n",
            "Added in second: –are computed as follows:\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: }\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "Added in second: and\n",
            "Added in second: A\n",
            "Added in second: is the set of alignments between all reads and transcripts. In the following M step, then, the fragments of reads assigned to each transcript are summed up and then normalized by the total number of transcripts to get the relative transcript abundances, expressed as:\n",
            "Added in second: where\n",
            "Added in second: R\n",
            "Added in second: t\n",
            "Added in second: is the set of reads aligned to transcript\n",
            "Added in second: t\n",
            "Added in second: . The denominator is constant across iterations and is equivalent to the total number of reads in a long-read RNA-seq experiment where each read represents a transcript, so we precompute this value before EM.\n",
            "Added in second: Initialization\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "Added in second: where\n",
            "Added in second: T\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: R\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: X\n",
            "Added in second: of dimensions\n",
            "Added in second: N\n",
            "Added in second: rows and\n",
            "Added in second: M\n",
            "Added in second: columns. For simplicity, we’ll refer to\n",
            "Added in second: X\n",
            "Added in second: as the compatibility score matrix. The computation specified in\n",
            "Added in second: Eq. 7\n",
            "Added in second: is further simplified as:\n",
            "Added in second: The pre-computation step involves a single scan over the alignment results, extracting values such as the alignment scores and alignment start/end positions, and then applying the definitions provided in\n",
            "Added in second: Eqs. 3\n",
            "Added in second: and 4.\n",
            "Added in second: Optimization\n",
            "Added in second: Once\n",
            "Added in second: X\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: The novelty of our method comes from guiding the EM algorithm with the priors extracted from the alignment results, as detailed in the E-step update rule shown in\n",
            "Added in second: Eq. 9\n",
            "Added in second: . To further amplify the impact of these priors, we implemented an algorithm called the\n",
            "Added in second: drop\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm (Supplementary Figure S4) sets\n",
            "Added in second: X\n",
            "Added in second: rt\n",
            "Added in second: = 0 if the fraction of read\n",
            "Added in second: r\n",
            "Added in second: that is assigned to transcript\n",
            "Added in second: t\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: r\n",
            "Added in second: and transcript\n",
            "Added in second: t\n",
            "Added in second: and ensures that no fraction of\n",
            "Added in second: r\n",
            "Added in second: gets assigned to\n",
            "Added in second: t\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: will always be 0 since its computation involves multiplication by\n",
            "Added in second: X\n",
            "Added in second: rt\n",
            "Added in second: (\n",
            "Added in second: Eq. 9\n",
            "Added in second: ). After the drop, another E-step is performed with the updated\n",
            "Added in second: X\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "Added in second: r\n",
            "Added in second: considered, and by default:\n",
            "Added in second: where\n",
            "Added in second: T\n",
            "Added in second: r\n",
            "Added in second: is the set of transcripts that are compatible with\n",
            "Added in second: r\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: Pachter, 2011\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -51768 +53177,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -51776 +53191,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -51779 +53200,7 @@\n",
            "\n",
            "Removed from first: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters ν, ω approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter ω models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "Added in second: Graphical representation of TranSigner’s long-read RNA-seq model. Empty circles denote latent variables, the shaded circle represents the observed variable, and the blue circle indicates the primary parameter of the model – specifically, the relative abundance of the transcript. Parameters\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: approximate the likelihood of the specific 5’ and 3’ end positions of the read on the transcript, while parameter\n",
            "Added in second: σ\n",
            "Added in second: models the likelihood of observing a specific read sequence given a transcript and the read’s end positions.\n",
            "\n",
            "--- Context around line @@ -51783,3 +53210,3 @@\n",
            "\n",
            "Removed from first: Existing RNA-seq quantification methods focus on accurately estimating ρ, the relative transcript abundances (\n",
            "Removed from first: Jousheghani & Patro, 2024\n",
            "Removed from first: ;\n",
            "Added in second: Existing RNA-seq quantification methods focus on accurately estimating\n",
            "Added in second: ρ\n",
            "Added in second: , the relative transcript abundances (Jousheghani & Patro, 2024;\n",
            "\n",
            "--- Context around line @@ -51789 +53216,9 @@\n",
            "\n",
            "Removed from first: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not ρ. However, deriving a maximum likelihood (ML) estimate on ρ also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence, ρ is still the main parameter to optimize, and we define our objective with respect to ρ as follows. Given a set of transcripts\n",
            "Added in second: ). In contrast, our primary goal here is to assign reads to transcripts, which is solved by finding the most probable distributions over the latent variables, not\n",
            "Added in second: ρ\n",
            "Added in second: . However, deriving a maximum likelihood (ML) estimate on\n",
            "Added in second: ρ\n",
            "Added in second: also gets us ML estimates on the latent variable distributions, as they get repeatedly updated in the process of optimization. Hence,\n",
            "Added in second: ρ\n",
            "Added in second: is still the main parameter to optimize, and we define our objective with respect to\n",
            "Added in second: ρ\n",
            "Added in second: as follows. Given a set of transcripts\n",
            "\n",
            "--- Context around line @@ -51798 +53233,4 @@\n",
            "\n",
            "Removed from first: where ρ = {ρ\n",
            "Added in second: where\n",
            "Added in second: ρ\n",
            "Added in second: = {\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51801,3 +53239 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ϵ\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -51841 +53277,4 @@\n",
            "\n",
            "Removed from first: |ρ) = ρ\n",
            "Added in second: |\n",
            "Added in second: ρ\n",
            "Added in second: ) =\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -51848 +53287,2 @@\n",
            "\n",
            "Removed from first: where α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51876 +53316,2 @@\n",
            "\n",
            "Removed from first: ) corresponds to a smaller α\n",
            "Added in second: ) corresponds to a smaller\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -51878 +53319,3 @@\n",
            "\n",
            "Removed from first: . Moreover, optimizing ℒ involves driving\n",
            "Added in second: . Moreover, optimizing\n",
            "Added in second: L\n",
            "Added in second: involves driving\n",
            "\n",
            "--- Context around line @@ -51895 +53338,5 @@\n",
            "\n",
            "Removed from first: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables– ν and ω for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "Added in second: ). Nonetheless, long reads are more likely to cover all bases of a transcript, compared to short reads, which are generated from fragments of the transcript. The likelihood of a read’s end position should decrease as its distance from the transcript end increases. We model this expectation using two indicator variables–\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: for the 3’ and 5’ ends, respectively – to control how far apart the ends of a read can be from the ends of a transcript. For an alignment between a read\n",
            "\n",
            "--- Context around line @@ -51899,13 +53346,7 @@\n",
            "\n",
            "Removed from first: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: for the 5’ and 3’ ends, respectively. Then we define ν and ω as:\n",
            "Removed from first: where δ\n",
            "Removed from first: rt′\n",
            "Removed from first: s\n",
            "Removed from first: and δ\n",
            "Removed from first: rt′\n",
            "Removed from first: e\n",
            "Added in second: , we will refer to the distances between the alignment ends and transcript ends as ‘end distances’ and denote them as\n",
            "Added in second: for the 5’ and 3’ ends, respectively. Then we define\n",
            "Added in second: υ\n",
            "Added in second: and\n",
            "Added in second: ω\n",
            "Added in second: as:\n",
            "Added in second: where\n",
            "\n",
            "--- Context around line @@ -51925,27 +53366,18 @@\n",
            "\n",
            "Removed from first: , end distances are computed as δ\n",
            "Removed from first: rt\n",
            "Removed from first: s\n",
            "Removed from first: =\n",
            "Removed from first: s\n",
            "Removed from first: rt\n",
            "Removed from first: =\n",
            "Removed from first: i\n",
            "Removed from first: and δ\n",
            "Removed from first: rt\n",
            "Removed from first: e\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: e\n",
            "Removed from first: rt\n",
            "Removed from first: = |\n",
            "Removed from first: t\n",
            "Removed from first: | –\n",
            "Removed from first: j\n",
            "Removed from first: is the length of transcript\n",
            "Removed from first: t\n",
            "Removed from first: . Parameter β represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Removed from first: r\n",
            "Removed from first: . This relative thresholding on end distances (δ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Removed from first: t\n",
            "Removed from first: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either ν or ω is set to 0, Ρ(\n",
            "Added in second: , end distances are computed as\n",
            "Added in second: where |\n",
            "Added in second: t\n",
            "Added in second: | is the length of transcript\n",
            "Added in second: t\n",
            "Added in second: . Parameter\n",
            "Added in second: β\n",
            "Added in second: represents the tolerance threshold on how much greater the end distances can be compared to the primary alignment’s end distances for a given read\n",
            "Added in second: r\n",
            "Added in second: . This relative thresholding on end distances (\n",
            "Added in second: δ\n",
            "Added in second: ) ensures that each read is compatible with at least one transcript (i.e.,\n",
            "Added in second: t\n",
            "Added in second: ′) after this filtering step since the primary alignment will always be considered “good,” which would not be true if a constant threshold was uniformly applied for all reads. When either\n",
            "Added in second: υ\n",
            "Added in second: or\n",
            "Added in second: ω\n",
            "Added in second: is set to 0, Ρ(\n",
            "\n",
            "--- Context around line @@ -51976 +53408,11 @@\n",
            "\n",
            "Removed from first: ). We set the β parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are ν = −∞ (i.e., no filter) and ω = −800, while for ONT cDNA and PacBio data, they are ν = −500 (i.e., unset) and ω = −550 for ONT cDNA and PacBio data.\n",
            "Added in second: ). We set the\n",
            "Added in second: β\n",
            "Added in second: parameter values based on both prior knowledge and a grid search (Supplementary Text 1). For the ONT direct RNA data, the current default values are\n",
            "Added in second: υ\n",
            "Added in second: = −∞ (i.e., no filter) and\n",
            "Added in second: ω\n",
            "Added in second: = −800, while for ONT cDNA and PacBio data, they are\n",
            "Added in second: υ\n",
            "Added in second: = −500 (i.e., unset) and\n",
            "Added in second: ω\n",
            "Added in second: = −550 for ONT cDNA and PacBio data.\n",
            "\n",
            "--- Context around line @@ -51997 +53439,2 @@\n",
            "\n",
            "Removed from first: , with ν\n",
            "Added in second: , with\n",
            "Added in second: υ\n",
            "\n",
            "--- Context around line @@ -51999 +53442,2 @@\n",
            "\n",
            "Removed from first: , ω\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "\n",
            "--- Context around line @@ -52001 +53445,2 @@\n",
            "\n",
            "Removed from first: , and σ\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "\n",
            "--- Context around line @@ -52008 +53453,2 @@\n",
            "\n",
            "Removed from first: which shows how α\n",
            "Added in second: which shows how\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52024 +53470,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -52028 +53478,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -52030,2 +53488 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -52035 +53492,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52038 +53498,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -52049 +53512,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -52052 +53517,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -52054 +53520,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -52068 +53540 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -52071 +53543,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -52085 +53559,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52087 +53562,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -52095 +53572,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52104 +53582,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52106 +53585,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -52114 +53595,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -52116,3 +53599,11 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "\n",
            "--- Context around line @@ -52120 +53611,5 @@\n",
            "\n",
            "Removed from first: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced α as a variable representing read-to-transcript assignments and established that the distribution over α is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "Added in second: Our primary goal is to accurately assign reads to their respective transcript origins. We previously introduced\n",
            "Added in second: α\n",
            "Added in second: as a variable representing read-to-transcript assignments and established that the distribution over\n",
            "Added in second: α\n",
            "Added in second: is equivalent to that over the latent variables of our long-read RNA-seq model (\n",
            "\n",
            "--- Context around line @@ -52124 +53619,9 @@\n",
            "\n",
            "Removed from first: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g., ρ) through iterative updates to the distribution over a set of latent variables (e.g., α). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over α and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on ρ.\n",
            "Added in second: , 2, 3). An expectation-maximum (EM) algorithm finds a maximum likelihood (ML) estimate for a main parameter (e.g.,\n",
            "Added in second: ρ\n",
            "Added in second: ) through iterative updates to the distribution over a set of latent variables (e.g.,\n",
            "Added in second: α\n",
            "Added in second: ). Hence, TranSigner employs an EM algorithm to obtain the most probable–in the sense that the complete data likelihood is maximized– distribution over\n",
            "Added in second: α\n",
            "Added in second: and presents the corresponding expected values as read-to-transcript assignments. It also outputs the ML estimates on\n",
            "Added in second: ρ\n",
            "Added in second: .\n",
            "\n",
            "--- Context around line @@ -52126,2 +53629 @@\n",
            "\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Added in second: . The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for\n",
            "\n",
            "--- Context around line @@ -52131 +53633,4 @@\n",
            "\n",
            "Removed from first: where α = {α\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "Added in second: = {\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52134 +53639,4 @@\n",
            "\n",
            "Removed from first: r,tϵA\n",
            "Added in second: r\n",
            "Added in second: ,\n",
            "Added in second: t\n",
            "Added in second: ∈.\n",
            "\n",
            "--- Context around line @@ -52144,19 +53651,0 @@\n",
            "\n",
            "Removed from first: Update rules\n",
            "Removed from first: The EM algorithm consists of alternating expectation (E) and maximization (M) steps, repeated until convergence. During the E step, the expected values for α\n",
            "Removed from first: (+)\n",
            "Removed from first: –at some iteration\n",
            "Removed from first: n\n",
            "Removed from first: –are computed as follows:\n",
            "Removed from first: where α = {α\n",
            "Removed from first: rt\n",
            "Removed from first: }\n",
            "Removed from first: r,tϵA\n",
            "Removed from first: and\n",
            "Removed from first: A\n",
            "Removed from first: is the set of alignments between all reads and transcripts. In the following M step, then, the fragments of reads assigned to each transcript are summed up and then normalized by the total number of transcripts to get the relative transcript abundances, expressed as:\n",
            "Removed from first: where\n",
            "Removed from first: R\n",
            "Removed from first: t\n",
            "Removed from first: is the set of reads aligned to transcript\n",
            "Removed from first: t\n",
            "Removed from first: . The denominator is constant across iterations and is equivalent to the total number of reads in a long-read RNA-seq experiment where each read represents a transcript, so we precompute this value before EM.\n",
            "\n",
            "--- Context around line @@ -52164 +53653,3 @@\n",
            "\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -52167 +53658,2 @@\n",
            "\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -52169 +53661,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -52183,41 +53681,4 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Removed from first: Once\n",
            "Removed from first: X\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Removed from first: The novelty of our method comes from guiding the EM algorithm with the priors extracted from the alignment results, as detailed in the E-step update rule shown in\n",
            "Removed from first: Eq. 9\n",
            "Removed from first: . To further amplify the impact of these priors, we implemented an algorithm called the\n",
            "Removed from first: drop\n",
            "Removed from first: . The\n",
            "Removed from first: drop\n",
            "Removed from first: algorithm (Supplementary Figure S4) sets\n",
            "Removed from first: X\n",
            "Removed from first: rt\n",
            "Removed from first: = 0 if the fraction of read\n",
            "Removed from first: r\n",
            "Removed from first: that is assigned to transcript\n",
            "Removed from first: t\n",
            "Removed from first: (i.e., α\n",
            "Removed from first: rt\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Removed from first: r\n",
            "Removed from first: and transcript\n",
            "Removed from first: t\n",
            "Removed from first: and ensures that no fraction of\n",
            "Removed from first: r\n",
            "Removed from first: gets assigned to\n",
            "Removed from first: t\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Removed from first: rt\n",
            "Removed from first: will always be 0 since its computation involves multiplication by\n",
            "Removed from first: X\n",
            "Removed from first: rt\n",
            "Removed from first: (\n",
            "Removed from first: Eq. 9\n",
            "Removed from first: ). After the drop, another E-step is performed with the updated\n",
            "Removed from first: X\n",
            "Removed from first: scores to recompute the new α\n",
            "Removed from first: rt\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Removed from first: r\n",
            "Removed from first: considered, and by default:\n",
            "Added in second: Initialization\n",
            "Added in second: Before the EM iterations, the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) are initialized to the uniform distribution:\n",
            "\n",
            "--- Context around line @@ -52226,13 +53687,2 @@\n",
            "\n",
            "Removed from first: r\n",
            "Removed from first: is the set of transcripts that are compatible with\n",
            "Removed from first: r\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Removed from first: Pachter, 2011\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Removed from first: Initialization\n",
            "Removed from first: Before the EM iterations, the relative transcript abundances (ρ) are initialized to the uniform distribution:\n",
            "Removed from first: where\n",
            "Removed from first: T\n",
            "Removed from first: . is the set of transcripts with at least one alignment to a read in\n",
            "Added in second: A\n",
            "Added in second: is the set of transcripts with at least one alignment to a read in\n",
            "\n",
            "--- Context around line @@ -52240 +53690,7 @@\n",
            "\n",
            "Removed from first: . Additionally, the values for ν, ω, and ω don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "Added in second: . Additionally, the values for\n",
            "Added in second: υ\n",
            "Added in second: ,\n",
            "Added in second: ω\n",
            "Added in second: , and\n",
            "Added in second: σ\n",
            "Added in second: don’t change during iterations, so we precompute their values and store them separately in a matrix\n",
            "\n",
            "--- Context around line @@ -52254 +53710 @@\n",
            "\n",
            "Removed from first: Optimization.\n",
            "Added in second: Optimization\n",
            "\n",
            "--- Context around line @@ -52257 +53713,3 @@\n",
            "\n",
            "Removed from first: is precomputed and ρ is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "\n",
            "--- Context around line @@ -52271 +53729,2 @@\n",
            "\n",
            "Removed from first: (i.e., α\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52273 +53732,3 @@\n",
            "\n",
            "Removed from first: ) gets below a threshold, τ ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "\n",
            "--- Context around line @@ -52281 +53742,2 @@\n",
            "\n",
            "Removed from first: in any iterations following the drop, as α\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52290 +53752,2 @@\n",
            "\n",
            "Removed from first: scores to recompute the new α\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52292 +53755,3 @@\n",
            "\n",
            "Removed from first: values. The τ value depends on the read\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "\n",
            "--- Context around line @@ -52300 +53765,3 @@\n",
            "\n",
            "Removed from first: . The drop algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "\n",
            "--- Context around line @@ -52302,3 +53769,113 @@\n",
            "\n",
            "Removed from first: ), which relies solely on the relative transcript abundances (ρ) in its E-step update.\n",
            "Removed from first: Read assignment.\n",
            "Removed from first: We can use the α values estimated by the EM algorithm to infer read assignments to transcripts. Raw α values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the α values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw α values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding α value. It then recomputes the relative transcript abundances based on these hard assignments. These new α and ρ values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Optimization\n",
            "Added in second: Once\n",
            "Added in second: X\n",
            "Added in second: is precomputed and\n",
            "Added in second: ρ\n",
            "Added in second: is initialized, EM iterations are repeated until convergence, i.e., until the total sum of changes in the relative transcript abundances is less than a predefined threshold, by default set at 0.005. The user can adjust this threshold to increase the accuracy of the ML estimates at the expense of speed.\n",
            "Added in second: The novelty of our method comes from guiding the EM algorithm with the priors extracted from the alignment results, as detailed in the E-step update rule shown in\n",
            "Added in second: Eq. 9\n",
            "Added in second: . To further amplify the impact of these priors, we implemented an algorithm called the\n",
            "Added in second: drop\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm (Supplementary Figure S4) sets\n",
            "Added in second: X\n",
            "Added in second: rt\n",
            "Added in second: = 0 if the fraction of read\n",
            "Added in second: r\n",
            "Added in second: that is assigned to transcript\n",
            "Added in second: t\n",
            "Added in second: (i.e.,\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: ) gets below a threshold,\n",
            "Added in second: τ\n",
            "Added in second: ∈ [0,1]. This effectively drops the compatibility relationship between read\n",
            "Added in second: r\n",
            "Added in second: and transcript\n",
            "Added in second: t\n",
            "Added in second: and ensures that no fraction of\n",
            "Added in second: r\n",
            "Added in second: gets assigned to\n",
            "Added in second: t\n",
            "Added in second: in any iterations following the drop, as\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: will always be 0 since its computation involves multiplication by\n",
            "Added in second: X\n",
            "Added in second: rt\n",
            "Added in second: (\n",
            "Added in second: Eq. 9\n",
            "Added in second: ). After the drop, another E-step is performed with the updated\n",
            "Added in second: X\n",
            "Added in second: scores to recompute the new\n",
            "Added in second: α\n",
            "Added in second: rt\n",
            "Added in second: values. The\n",
            "Added in second: τ\n",
            "Added in second: value depends on the read\n",
            "Added in second: r\n",
            "Added in second: considered, and by default:\n",
            "Added in second: where\n",
            "Added in second: T\n",
            "Added in second: r\n",
            "Added in second: is the set of transcripts that are compatible with\n",
            "Added in second: r\n",
            "Added in second: . The\n",
            "Added in second: drop\n",
            "Added in second: algorithm is called only right after the first E-step calculation, and its purpose is to discard minimap2 alignments that are not robust. The drop algorithm offers the potential to achieve a higher optimum compared to a naïve EM algorithm (\n",
            "Added in second: Pachter, 2011\n",
            "Added in second: ), which relies solely on the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) in its E-step update. We also allow users to increase this threshold (i.e., make it stricter) using the\n",
            "Added in second: -f\n",
            "Added in second: parameter that’ll increment\n",
            "Added in second: τ\n",
            "Added in second: r\n",
            "Added in second: by a fraction of its own value as follows:\n",
            "Added in second: where\n",
            "Added in second: f\n",
            "Added in second: is a fractional value within the range [0, 1].\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "Added in second: Read assignment\n",
            "Added in second: We can use the\n",
            "Added in second: α\n",
            "Added in second: values estimated by the EM algorithm to infer read assignments to transcripts. Raw\n",
            "Added in second: α\n",
            "Added in second: values represent fractional read assignments, where a single read may be distributed among multiple transcripts. These assignments might be challenging to interpret, as we assume each read to originate from a single transcript. To increase the interpretability and usability of the\n",
            "Added in second: α\n",
            "Added in second: values, we implemented the push algorithm (Supplementary Figure S5). This algorithm processes raw\n",
            "Added in second: α\n",
            "Added in second: values, converting them into hard assignments where each read is assigned to exactly one transcript. The push algorithm iterates through the reads and pairs each of them to the transcript with the highest read fraction as shown by the corresponding\n",
            "Added in second: α\n",
            "Added in second: value. It then recomputes the relative transcript abundances based on these hard assignments. These new\n",
            "Added in second: α\n",
            "Added in second: and\n",
            "Added in second: ρ\n",
            "Added in second: values may deviate from their EM-derived ML estimates, potentially resulting in reduced accuracy. We tested this using simulated data and observed only negligible reductions in accuracy.\n",
            "\n",
            "--- Context around line @@ -52320 +53897,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -52322 +53901,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -52348 +53931,3 @@\n",
            "\n",
            "Removed from first: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (ρ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "Added in second: Finally, the EM module takes as inputs the compatibility score matrix and the target transcriptome index from the prefilter module. It estimates the transcript coverage abundances using an expectation-maximization (EM) algorithm. The EM algorithm converges when the total change in the relative transcript abundances (\n",
            "Added in second: ρ\n",
            "Added in second: ) is less than a specified threshold, by default set to 0.05. The drop algorithm, described above and in Supplementary Figure S5, is implemented as a component of this module. It allows users to use the\n",
            "\n",
            "--- Context around line @@ -52350 +53935,5 @@\n",
            "\n",
            "Removed from first: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e., α estimates) and relative transcript abundances (i.e., ρ estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "Added in second: flag to remove low compatibility relations between reads and transcripts immediately after the first E-step update. Read-to-transcript assignments (i.e.,\n",
            "Added in second: α\n",
            "Added in second: estimates) and relative transcript abundances (i.e.,\n",
            "Added in second: ρ\n",
            "Added in second: estimates) are outputted as TSV files at the end of the EM module. Users also have the option to further process the assignments and output hard 1-to-1 assignments between reads and transcripts for increased interpretability by specifying the\n",
            "\n",
            "--- Context around line @@ -52354 +53943 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -52360 +53949 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -52362 +53951 @@\n",
            "\n",
            "Removed from first: Three sets of Oxford Nanopore Technologies (ONT) dRNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "Added in second: Three sets of Oxford Nanopore Technologies (ONT) direct RNA reads and two sets of ONT cDNA reads were simulated using NanoSim (\n",
            "\n",
            "--- Context around line @@ -52368 +53957 @@\n",
            "\n",
            "Removed from first: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each dRNA read set, we generated ∼14 million ONT dRNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "Added in second: ) in its alignment-based mode. We used the RefSeq annotation as the target transcriptome. Salmon estimates were then used as input for the NanoSim simulation module. For each direct RNA read set, we generated ∼14 million ONT direct RNA reads, and ∼25 million for each cDNA read set (Supplementary Text 5).\n",
            "\n",
            "--- Context around line @@ -52375 +53964 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -52377 +53966,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -52383 +53974 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -52391 +53982 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -52393 +53984,3 @@\n",
            "\n",
            "Removed from first: where α is the set of raw abundances provided by SG-Nex,\n",
            "Added in second: where\n",
            "Added in second: a\n",
            "Added in second: is the set of raw abundances provided by SG-Nex,\n",
            "\n",
            "--- Context around line @@ -52399 +53992 @@\n",
            "\n",
            "Removed from first: i\n",
            "Added in second: s\n",
            "\n",
            "--- Context around line @@ -52403 +53996 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -52410 +54003 @@\n",
            "\n",
            "Removed from first: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods, including Oarfish, NanoCount, and TranSigner, on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (Supplementary Text 3). We repeated the same steps for two other organisms:\n",
            "Added in second: The goal with paired RNA-seq data sets is to compute the correlation between the short- and long-read-derived transcript abundance estimates. Long reads are first aligned to the GRCh38 genome using minimap2 and the resulting alignments are provided to StringTie2 for a transcriptome assembly. Short reads are then quantified on the long-read-derived StringTie2 transcripts using Salmon. Afterward, we ran quantification-only methods – NanoCount and TranSigner – on the StringTie2 assembly to obtain long-read-derived abundance estimates. We evaluated these tools’ estimates based on their nonlinear correlation with Salmon’s short-read-derived estimates (see Supplementary Text 3 for the commands used for short-read quantification). We repeated the same steps for two other organisms:\n",
            "\n",
            "--- Context around line @@ -52438 +54031,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -52443,3 +54037 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -52455 +54047 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -52465,2 +54057,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52490 +54085,2 @@\n",
            "\n",
            "Removed from first: (denoted as ρ\n",
            "Added in second: (denoted as\n",
            "Added in second: ρ\n",
            "\n",
            "--- Context around line @@ -52495,3 +54091 @@\n",
            "\n",
            "Removed from first: t\n",
            "Removed from first: ∈\n",
            "Removed from first: T\n",
            "Added in second: t∈T\n",
            "\n",
            "--- Context around line @@ -52507 +54101 @@\n",
            "\n",
            "Removed from first: ∗ 10\n",
            "Added in second: * 10\n",
            "\n",
            "--- Context around line @@ -52517,2 +54111,5 @@\n",
            "\n",
            "Removed from first: assigned to each transcript in that list, or the α estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Removed from first: where α\n",
            "Added in second: assigned to each transcript in that list, or the\n",
            "Added in second: α\n",
            "Added in second: estimates. These assignments can be used to compute coverage estimates for transcripts as\n",
            "Added in second: where\n",
            "Added in second: α\n",
            "\n",
            "--- Context around line @@ -52541 +54138 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -52550 +54147 @@\n",
            "\n",
            "Removed from first: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "Added in second: for cDNA reads); FLAIR had its own align module. Unlike StringTie2 and FLAIR which output an annotation containing only the identified expressed transcripts, Bambu outputs both expressed and unexpressed transcripts in the guide annotation (see Supplementary Text 2). Therefore, for our evaluations, we removed any transcript that was assigned a zero read count from Bambu’s output.\n",
            "\n",
            "--- Context around line @@ -52564 +54161 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -52566 +54163 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -52567,0 +54165,6 @@\n",
            "\n",
            "Added in second: Competing interests\n",
            "Added in second: The authors have declared no competing interests.\n",
            "Added in second: Funding\n",
            "Added in second: This work was supported in part by the US National Institutes of Health under grants R01-HG006677, and R01-MH123567. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n",
            "Added in second: Authors’ contributions\n",
            "Added in second: HJJ and MP designed the study. HJJ wrote the software and code used for benchmarking. HJJ and MP evaluate analysis results and wrote / revised the manuscript. HJJ prepared all (main and supplementary) figures. All authors read and approved the final manuscript.\n",
            "\n",
            "--- Context around line @@ -52585 +54188 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -52587 +54190 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -52597 +54200 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13267932\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334738\n",
            "\n",
            "--- Context around line @@ -52599 +54202 @@\n",
            "\n",
            "Removed from first: https://doi.org/10.5281/zenodo.13307396\n",
            "Added in second: https://doi.org/10.5281/zenodo.13334733\n",
            "\n",
            "--- Context around line @@ -52613 +54216 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -52615 +54218 @@\n",
            "\n",
            "Removed from first: Acknowledgments.\n",
            "Added in second: Acknowledgments\n",
            "\n",
            "--- Context around line @@ -52618 +54221 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -52620 +54223 @@\n",
            "\n",
            "Removed from first: Figures 1 through 6 revised to include results from additional data sets; Figures 7 and 8 added to the Results section; Results section updated to describe additional benchmarks on simulated and experimental data; Methods section updated to clarify the mathematical foundation of TranSigner and remove stale descriptions; Supplemental files updated to include additional analysis results and more detailed description of the benchmark process; Supplementary Figures 1 through 3 revised.\n",
            "Added in second: Figures 1, 2, 4, 7 and 8 updated; main text updated accordingly; supplementary tables and texts also updated.\n",
            "\n",
            "--- Context around line @@ -52622 +54224,0 @@\n",
            "\n",
            "Removed from first: 1.\n",
            "\n",
            "--- Context around line @@ -52722 +54323,0 @@\n",
            "\n",
            "Removed from first: 2.\n",
            "\n",
            "--- Context around line @@ -52765 +54365,0 @@\n",
            "\n",
            "Removed from first: 3.\n",
            "\n",
            "--- Context around line @@ -52792 +54391,0 @@\n",
            "\n",
            "Removed from first: 4.\n",
            "\n",
            "--- Context around line @@ -52869 +54468,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -52889 +54489,0 @@\n",
            "\n",
            "Removed from first: 5.\n",
            "\n",
            "--- Context around line @@ -52941 +54540,0 @@\n",
            "\n",
            "Removed from first: 6.\n",
            "\n",
            "--- Context around line @@ -53009 +54607,0 @@\n",
            "\n",
            "Removed from first: 7.\n",
            "\n",
            "--- Context around line @@ -53110 +54707,0 @@\n",
            "\n",
            "Removed from first: 8.\n",
            "\n",
            "--- Context around line @@ -53161,3 +54758 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -53166 +54760,0 @@\n",
            "\n",
            "Removed from first: 9.\n",
            "\n",
            "--- Context around line @@ -53214 +54807,0 @@\n",
            "\n",
            "Removed from first: 10.\n",
            "\n",
            "--- Context around line @@ -53249 +54841,0 @@\n",
            "\n",
            "Removed from first: 11.\n",
            "\n",
            "--- Context around line @@ -53280,30 +54871,0 @@\n",
            "\n",
            "Removed from first: 12.\n",
            "Removed from first: ↵\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: 13.\n",
            "\n",
            "--- Context around line @@ -53349 +54910,0 @@\n",
            "\n",
            "Removed from first: 14.\n",
            "\n",
            "--- Context around line @@ -53391 +54951,0 @@\n",
            "\n",
            "Removed from first: 15.\n",
            "\n",
            "--- Context around line @@ -53416 +54975,0 @@\n",
            "\n",
            "Removed from first: 16.\n",
            "\n",
            "--- Context around line @@ -53441 +54999,0 @@\n",
            "\n",
            "Removed from first: 17.\n",
            "\n",
            "--- Context around line @@ -53542 +55099,0 @@\n",
            "\n",
            "Removed from first: 18.\n",
            "\n",
            "--- Context around line @@ -53559 +55115,0 @@\n",
            "\n",
            "Removed from first: 19.\n",
            "\n",
            "--- Context around line @@ -53639,2 +55195,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -53646 +55202,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -53654 +55215,0 @@\n",
            "\n",
            "Removed from first: 20.\n",
            "\n",
            "--- Context around line @@ -53695 +55255,0 @@\n",
            "\n",
            "Removed from first: 21.\n",
            "\n",
            "--- Context around line @@ -53712,3 +55272 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -53719 +55276,0 @@\n",
            "\n",
            "Removed from first: 22.\n",
            "\n",
            "--- Context around line @@ -53762 +55318,0 @@\n",
            "\n",
            "Removed from first: 23.\n",
            "\n",
            "--- Context around line @@ -53840 +55395,0 @@\n",
            "\n",
            "Removed from first: 24.\n",
            "\n",
            "--- Context around line @@ -53871 +55425,0 @@\n",
            "\n",
            "Removed from first: 25.\n",
            "\n",
            "--- Context around line @@ -54376 +55930,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -54471 +56027,3 @@\n",
            "\n",
            "Removed from first: ,…consortium, S.-N. (\n",
            "Added in second: ,…\n",
            "Added in second: consortium, S.-N.\n",
            "Added in second: (\n",
            "\n",
            "--- Context around line @@ -54970,3 +56528 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -55024,3 +56580 @@\n",
            "\n",
            "Removed from first: ),\n",
            "Removed from first: eabq5072\n",
            "Removed from first: .\n",
            "Added in second: ), eabq5072.\n",
            "\n",
            "--- Context around line @@ -55245,54 +56798,0 @@\n",
            "\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "Removed from first: Jousheghani\n",
            "Removed from first: ,\n",
            "Removed from first: Z. Z.\n",
            "Removed from first: , &\n",
            "Removed from first: Patro\n",
            "Removed from first: ,\n",
            "Removed from first: R\n",
            "Removed from first: . (\n",
            "Removed from first: 2024\n",
            "Removed from first: ).\n",
            "Removed from first: Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification\n",
            "Removed from first: .\n",
            "Removed from first: bioRxiv\n",
            "Removed from first: ,\n",
            "Removed from first: 2024\n",
            "Removed from first: .\n",
            "Removed from first: 2002\n",
            "Removed from first: .\n",
            "Removed from first: 2028\n",
            "Removed from first: .582591.\n",
            "Removed from first: doi:\n",
            "Removed from first: 10.1101/2024.02.28.582591\n",
            "Removed from first: OpenUrl\n",
            "Removed from first: Abstract\n",
            "Removed from first: /\n",
            "Removed from first: FREE\n",
            "Removed from first: Full Text\n",
            "\n",
            "--- Context around line @@ -55853,2 +57353,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -55860 +57360,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -55946,2 +57452,2 @@\n",
            "\n",
            "Removed from first: A. N.\n",
            "Removed from first: (\n",
            "Added in second: A. N\n",
            "Added in second: . (\n",
            "\n",
            "--- Context around line @@ -55953 +57459,7 @@\n",
            "\n",
            "Removed from first: , 2023.2007.2025.550582.\n",
            "Added in second: ,\n",
            "Added in second: 2023\n",
            "Added in second: .\n",
            "Added in second: 2007\n",
            "Added in second: .\n",
            "Added in second: 2025\n",
            "Added in second: .550582.\n",
            "\n",
            "--- Context around line @@ -56054,3 +57566 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -56076,3 +57586 @@\n",
            "\n",
            "Removed from first: (\n",
            "Removed from first: 304\n",
            "Removed from first: ).\n",
            "Added in second: (304).\n",
            "\n",
            "--- Context around line @@ -56583 +58091 @@\n",
            "\n",
            "Removed from first: Posted August 13, 2024.\n",
            "Added in second: Posted August 17, 2024.\n",
            "\n",
            "--- Context around line @@ -56705 +58213 @@\n",
            "\n",
            "Removed from first: Posted August 13, 2024.\n",
            "Added in second: Posted August 17, 2024.\n",
            "\n",
            "--- Context around line @@ -56827 +58335 @@\n",
            "\n",
            "Removed from first: Posted August 13, 2024.\n",
            "Added in second: Posted August 17, 2024.\n",
            "\n",
            "--- Context around line @@ -56954,2 +58462,2 @@\n",
            "\n",
            "Removed from first: Posted August 13, 2024.\n",
            "Removed from first: Posted August 13, 2024.\n",
            "Added in second: Posted August 17, 2024.\n",
            "Added in second: Posted August 17, 2024.\n"
          ]
        }
      ]
    }
  ]
}